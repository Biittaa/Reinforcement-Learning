# Reinforcement Learning Basics: MDP & Cliff Walking

This project explores the fundamentals of **Reinforcement Learning (RL)** through two classic problems: a **Markov Decision Process (MDP)** for a coin-based betting game, and the well-known **Cliff Walking** scenario using tabular methods.

## üîç Project Overview

The project is divided into two main parts:

### Part 1: MDP - Coin Betting Game
- Models a simplified betting game using **Markov Decision Processes (MDP)**.
- Solves the problem using:
  - **Value Iteration**
  - **Policy Iteration**
- Compares convergence speed and results of both methods.

### Part 2: Cliff Walking
- Simulates the classic "Cliff Walking" gridworld environment.
- Implements and compares:
  - **Q-learning**
  - **SARSA**
- Explores the effect of different **epsilon values** and **exploration strategies**.

## üß† Concepts Used
- Markov Decision Processes (MDP)
- Value Iteration & Policy Iteration
- Tabular Q-learning & SARSA
- Exploration vs. Exploitation
- Epsilon-greedy strategy

## üìÅ Files
- `P1.ipynb`: Implementation of Part 1 (MDP problem)
- `P2.ipynb`: Implementation of Part 2 (Cliff Walking problem)
